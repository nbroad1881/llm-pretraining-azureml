{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: sandbox_east2_config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import ModelType\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from azure.ai.ml import MLClient, command, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Environment, BuildContext, AmlCompute\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient.from_config(credential, path=\"sandbox_east2_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"custom-decoder\"\n",
    "DATA_PREP_DIR = \"data_prep\"\n",
    "TRAIN_DIR = \"train\"\n",
    "ENV_FILENAME = \"env.yaml\"\n",
    "DATA_PREP_ENV_NAME = \"data_prep_env\"\n",
    "TRAIN_ENV_NAME = \"train_env\"\n",
    "DATA_PREP_COMPUTE_NAME = \"cpu-tokenization\"\n",
    "DATA_PREP_INSTANCE_TYPE = \"Standard_DS3_v2\"\n",
    "TRAIN_COMPUTE_NAME = \"run-clm-deepspeed\"\n",
    "TRAIN_INSTANCE_TYPE = \"Standard_NC24s_v3\"\n",
    "\n",
    "DATASTORE_NAME = \"workspaceartifactstore\"\n",
    "\n",
    "DATASTORE_TOKENIZER_PATH = \"blob_data/tokenizer\"\n",
    "DATASTORE_DATA_PATH = \"blob_data/data\"\n",
    "SEQUENCE_LENGTH = 2048\n",
    "DATA_PREP_NUM_PROCESSES = 4\n",
    "TOKENIZED_DATASET_PATH = \"blob_data/tokenized\"\n",
    "SAMPLES_PER_FILE = 200_000\n",
    "\n",
    "DATASTORE_MODEL_CONFIG_PATH = \"./5B_model_config.json\"\n",
    "DEEPSPEED_CONFIG = \"./deepspeed_config.json\"\n",
    "\n",
    "# YearMonthDayHourMinute\n",
    "timenow = datetime.utcnow().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "TRAINING_OUTPUT_PATH = \"gpt-bigcode-\"+timenow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to create/get environments/compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_compute_target(\n",
    "    ml_client,\n",
    "    compute_name,\n",
    "    instance_type=\"STANDARD_DS3_v2\",\n",
    "    min_nodes=0,\n",
    "    max_nodes=1,\n",
    "    idle_time=300,\n",
    "):\n",
    "    try:\n",
    "        cmpute = ml_client.compute.get(compute_name)\n",
    "        cmpute_name = cmpute.name\n",
    "    except Exception:\n",
    "        print(f\"Creating a new {instance_type} compute target...\")\n",
    "        compute = AmlCompute(\n",
    "            name=compute_name,\n",
    "            size=instance_type,\n",
    "            min_instances=min_nodes,\n",
    "            max_instances=max_nodes,\n",
    "            idle_time_before_scale_down=idle_time,\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute)\n",
    "        cmpute_name = compute.name\n",
    "    return cmpute_name\n",
    "\n",
    "\n",
    "def get_environment(\n",
    "    environment_name, dependencies_dir, ml_client, gpu=False, dep_yaml=None\n",
    "):\n",
    "    try:\n",
    "        env = ml_client.environments.get(name=environment_name)\n",
    "    except Exception:\n",
    "        if gpu:\n",
    "            image = \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04:latest\"\n",
    "        else:\n",
    "            image = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
    "        env = Environment(\n",
    "            name=environment_name,\n",
    "            description=\"Custom environment\",\n",
    "            conda_file=os.path.join(dependencies_dir, dep_yaml),\n",
    "            image=image,\n",
    "        )\n",
    "\n",
    "        env = ml_client.environments.create_or_update(env)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new Standard_DS3_v2 compute target...\n"
     ]
    }
   ],
   "source": [
    "data_prep_environment = get_environment(\n",
    "    environment_name=DATA_PREP_ENV_NAME,\n",
    "    dependencies_dir=DATA_PREP_DIR,\n",
    "    ml_client=ml_client,\n",
    "    gpu=False,\n",
    "    dep_yaml=ENV_FILENAME,\n",
    ")\n",
    "\n",
    "data_prep_compute = get_or_create_compute_target(\n",
    "        ml_client=ml_client,\n",
    "        compute_name=DATA_PREP_COMPUTE_NAME,\n",
    "        min_nodes=1,\n",
    "        max_nodes=1,\n",
    "        instance_type=DATA_PREP_INSTANCE_TYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_command = command(\n",
    "    name=\"data_prep\",\n",
    "    display_name=\"Data preparation for pretraining\",\n",
    "    description=\"reads in json files, creates tokenized Dataset\",\n",
    "    inputs={\n",
    "        \"train_data_dir\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{DATASTORE_DATA_PATH}/train\",\n",
    "            mode=\"ro_mount\",\n",
    "        ),\n",
    "        \"eval_data_dir\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{DATASTORE_DATA_PATH}/eval\",\n",
    "            mode=\"ro_mount\",\n",
    "        ),\n",
    "        \"max_seq_length\": SEQUENCE_LENGTH,\n",
    "        \"tokenizer_path\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{DATASTORE_TOKENIZER_PATH}\",\n",
    "            mode=\"ro_mount\",\n",
    "        ),\n",
    "        \"num_proc\": DATA_PREP_NUM_PROCESSES,\n",
    "        \"samples_per_file\": SAMPLES_PER_FILE,\n",
    "    },\n",
    "    outputs={\n",
    "        \"output_dir\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{TOKENIZED_DATASET_PATH}\",\n",
    "            mode=\"rw_mount\",\n",
    "        ),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=\"./data_prep\",\n",
    "    command=\"\"\"python run.py \\\n",
    "            --train_data_dir ${{inputs.train_data_dir}} \\\n",
    "            --eval_data_dir ${{inputs.eval_data_dir}} \\\n",
    "            --max_seq_length ${{inputs.max_seq_length}} \\\n",
    "            --tokenizer_path ${{inputs.tokenizer_path}} \\\n",
    "            --num_proc ${{inputs.num_proc}} \\\n",
    "            --samples_per_file ${{inputs.samples_per_file}} \\\n",
    "            --output_dir ${{outputs.output_dir}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{data_prep_environment.name}:{data_prep_environment.version}\",\n",
    "    compute=data_prep_compute\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_environment = get_environment(\n",
    "    environment_name=TRAIN_ENV_NAME,\n",
    "    dependencies_dir=TRAIN_DIR,\n",
    "    ml_client=ml_client,\n",
    "    gpu=True,\n",
    "    dep_yaml=ENV_FILENAME,\n",
    ")\n",
    "\n",
    "train_compute = get_or_create_compute_target(\n",
    "        ml_client=ml_client,\n",
    "        compute_name=TRAIN_COMPUTE_NAME,\n",
    "        min_nodes=1,\n",
    "        max_nodes=1,\n",
    "        instance_type=TRAIN_INSTANCE_TYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_command = command(\n",
    "    name=\"train\",\n",
    "    display_name=\"Train CLM model\",\n",
    "    description=\"Trains using CLM objective on tokenized data\",\n",
    "    inputs={\n",
    "        \"data_dir\": Input(type=\"uri_folder\"),\n",
    "        \"config_path\": DATASTORE_MODEL_CONFIG_PATH,\n",
    "        \"tokenizer_path\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{DATASTORE_TOKENIZER_PATH}\",\n",
    "            mode=\"ro_mount\",\n",
    "        ),\n",
    "        \"deepspeed_config_path\": DEEPSPEED_CONFIG,\n",
    "    },\n",
    "    outputs={\n",
    "        \"output_dir\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{TRAINING_OUTPUT_PATH}\",\n",
    "            mode=\"rw_mount\",\n",
    "        ),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=\"./train\",\n",
    "    command=\"\"\"torchrun --nnodes 1 --nproc_per_node 4 run.py \\\n",
    "            --data_dir ${{inputs.data_dir}} \\\n",
    "            --config_path ${{inputs.config_path}} \\\n",
    "            --tokenizer_path ${{inputs.tokenizer_path}} \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --evaluation_strategy epoch \\\n",
    "            --save_strategy epoch \\\n",
    "            --logging_steps 25 \\\n",
    "            --per_device_train_batch_size 1 \\\n",
    "            --per_device_eval_batch_size 1 \\\n",
    "            --learning_rate 3e-5 \\\n",
    "            --num_train_epochs 10 \\\n",
    "            --weight_decay 0.01 \\\n",
    "            --optim adamw_torch \\\n",
    "            --warmup_steps 100 \\\n",
    "            --fp16 \\\n",
    "            --output_dir ${{outputs.output_dir}} \\\n",
    "            --logging_dir ${{outputs.output_dir}} \\\n",
    "            --dataloader_num_workers 4 \\\n",
    "            --gradient_checkpointing True \\\n",
    "            --gradient_accumulation_steps 1 \\\n",
    "            --seed 42 \\\n",
    "            --report_to mlflow \\\n",
    "            --deepspeed ${{inputs.deepspeed_config_path}}\n",
    "            \"\"\",\n",
    "    environment=f\"{train_environment.name}:{train_environment.version}\",\n",
    "    compute=train_compute\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading train (0.01 MBs): 100%|██████████| 10551/10551 [00:00<00:00, 26083.73it/s]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    description=\"Pretraining decoder-only model using Deepspeed\",\n",
    "    display_name=f\"Deepspeed Pretraining\",\n",
    ")\n",
    "def pipeline_func():\n",
    "\n",
    "    data_prep_job = data_prep_command()\n",
    "\n",
    "    train_job = train_command(\n",
    "        data_dir=data_prep_job.outputs.output_dir,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_train_data\": data_prep_job.outputs.output_dir,\n",
    "    }\n",
    "\n",
    "pipeline = pipeline_func()\n",
    "\n",
    "\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"deepspeed\" + timenow,\n",
    ")\n",
    "\n",
    "# Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>deepspeed202306060411</td><td>keen_yogurt_7grjwmzvs8</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/keen_yogurt_7grjwmzvs8?wsid=/subscriptions/96f8b384-0587-41d4-9105-9fe6dca745b3/resourcegroups/nicholas-broad-azureml-rsg/workspaces/nicholasbroad&amp;tid=f40b18ba-b66c-49e4-9fd8-4fc7d3d19f0f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {'pipeline_job_train_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x12eb04b50>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': 'Pretraining decoder-only model using Deepspeed', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/Users/nicholasbroad/Documents/EAP/optum/deepspeed_clm', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12eb05e70>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'Deepspeed Pretraining', 'is_deterministic': None, 'inputs': {}, 'outputs': {'pipeline_job_train_data': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'data_prep_job': Command({'parameters': {}, 'init': False, 'name': 'data_prep_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/Users/nicholasbroad/Documents/EAP/optum/deepspeed_clm', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12eb064d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Data preparation for pretraining', 'experiment_name': None, 'compute': 'cpu-tokenization', 'services': None, 'comment': None, 'job_inputs': {'train_data_dir': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/paths/blob_data/data/train', 'mode': 'ro_mount'}, 'eval_data_dir': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/paths/blob_data/data/eval', 'mode': 'ro_mount'}, 'max_seq_length': '2048', 'tokenizer_path': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/paths/blob_data/tokenizer', 'mode': 'ro_mount'}, 'num_proc': '4', 'samples_per_file': '200000'}, 'job_outputs': {'output_dir': '${{parent.outputs.pipeline_job_train_data}}'}, 'inputs': {'train_data_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb04970>, 'eval_data_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb05f90>, 'max_seq_length': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb06e60>, 'tokenizer_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb05cc0>, 'num_proc': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb07130>, 'samples_per_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb04e80>}, 'outputs': {'output_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x12eb06320>}, 'component': 'azureml_anonymous:d865ec35-a3a2-4c51-a8e9-e12674d3e416', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '8dfe8c1b-31e8-4144-83eb-9fc348082e2c', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'train_job': Command({'parameters': {}, 'init': False, 'name': 'train_job', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/Users/nicholasbroad/Documents/EAP/optum/deepspeed_clm', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12eb05540>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Train CLM model', 'experiment_name': None, 'compute': 'run-clm-deepspeed', 'services': None, 'comment': None, 'job_inputs': {'config_path': './3B_model_config.json', 'tokenizer_path': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/paths/blob_data/tokenizer', 'mode': 'ro_mount'}, 'deepspeed_config_path': './deepspeed_config.json', 'data_dir': '${{parent.jobs.data_prep_job.outputs.output_dir}}'}, 'job_outputs': {'output_dir': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/paths/gpt-bigcode-202306060411', 'mode': 'rw_mount'}}, 'inputs': {'config_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb06380>, 'tokenizer_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb06440>, 'deepspeed_config_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb043d0>, 'data_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x12eb06140>}, 'outputs': {'output_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x12eb04580>}, 'component': 'azureml_anonymous:6879e8fa-9568-4c0f-9271-5cde6fe450b6', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'f64c885f-eea8-4c11-bff2-ef34c0dea357', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 2}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'keen_yogurt_7grjwmzvs8', 'description': 'Pretraining decoder-only model using Deepspeed', 'tags': {}, 'properties': {'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/96f8b384-0587-41d4-9105-9fe6dca745b3/resourceGroups/nicholas-broad-azureml-rsg/providers/Microsoft.MachineLearningServices/workspaces/nicholasbroad/jobs/keen_yogurt_7grjwmzvs8', 'Resource__source_path': None, 'base_path': '/Users/nicholasbroad/Documents/EAP/optum/deepspeed_clm', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x12eb04430>, 'serialize': <msrest.serialization.Serializer object at 0x12eb049a0>, 'display_name': 'Deepspeed Pretraining', 'experiment_name': 'deepspeed202306060411', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/96f8b384-0587-41d4-9105-9fe6dca745b3/resourceGroups/nicholas-broad-azureml-rsg/providers/Microsoft.MachineLearningServices/workspaces/nicholasbroad?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/keen_yogurt_7grjwmzvs8?wsid=/subscriptions/96f8b384-0587-41d4-9105-9fe6dca745b3/resourcegroups/nicholas-broad-azureml-rsg/workspaces/nicholasbroad&tid=f40b18ba-b66c-49e4-9fd8-4fc7d3d19f0f', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
